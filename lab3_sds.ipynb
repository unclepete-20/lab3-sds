{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtXcCFE0oAYZym1IXXrIrs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unclepete-20/lab3-sds/blob/main/lab3_sds.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Laboratorio de Detección de Malware mediante Secuencia de Llamadas a las APIs**\n",
        "\n",
        "## Integrantes:\n",
        "- Pedro Arriola (20188)\n",
        "- Andres de la Roca (20332)\n",
        "\n",
        "## Introducción\n",
        "\n",
        "En este laboratorio, exploraremos técnicas de detección de malware utilizando el análisis dinámico de la secuencia de llamadas a las APIs. El análisis dinámico ofrece información valiosa sobre el comportamiento de un malware y cómo interactúa con el sistema infectado. En lugar de depender únicamente del análisis estático, que puede ser fácilmente obstruido por técnicas de ofuscación, el análisis dinámico nos permite observar el orden en el tiempo en el que se ejecutan las llamadas a las APIs, lo que puede revelar patrones característicos de malware.\n",
        "\n",
        "En este laboratorio, utilizaremos un conjunto de datos que contiene la secuencia de llamadas a las APIs generadas por muestras de malware y software benigno. Implementaremos varios modelos de aprendizaje automático, incluidos Logistic Regression, Support Vector Machine (SVM) y Random Forest, para detectar y distinguir entre malware y software benigno basándonos en estas secuencias de llamadas a las APIs.\n",
        "\n",
        "A lo largo de este laboratorio, cubriremos las siguientes etapas del proceso de aprendizaje automático: exploración de datos, preprocesamiento de datos, ingeniería de características, implementación de modelos y evaluación de modelos utilizando métricas como precisión, recall y ROC AUC. Al finalizar el laboratorio, seremos capaces de comparar y evaluar la efectividad de diferentes modelos en la detección de malware basada en la secuencia de llamadas a las APIs.\n"
      ],
      "metadata": {
        "id": "IRP1ZDZiSRfa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao7PFhXNL6iN",
        "outputId": "71fb6628-6308-4d6f-cb05-ea0dd1f83b74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              sha256  labels  \\\n",
            "0  5c18291c481a192ed5003084dab2d8a117fd3736359218...       0   \n",
            "1  4683faf3da550ffb594cf5513c4cbb34f64df85f27fd1c...       0   \n",
            "2  9a0aea1c7290031d7c3429d0e921f107282cc6eab854ee...       0   \n",
            "3  e0f3e4d5f50afd9c31e51dd9941c5a52d57c7c524f5d11...       0   \n",
            "4  ec2b6d29992f13e74015ff0b129150b4afae15c593e4b7...       0   \n",
            "\n",
            "                     0                        1                   2  \\\n",
            "0         LdrUnloadDll           CoUninitialize          NtQueryKey   \n",
            "1         NtOpenMutant      GetForegroundWindow          NtQueryKey   \n",
            "2  GetForegroundWindow              DrawTextExW       GetSystemInfo   \n",
            "3      NtQueryValueKey             LdrUnloadDll  GlobalMemoryStatus   \n",
            "4         LdrUnloadDll  GetSystemTimeAsFileTime           NtOpenKey   \n",
            "\n",
            "                   3                            4                       5  \\\n",
            "0  NtDuplicateObject            GetShortPathNameW           GetSystemInfo   \n",
            "1        DrawTextExW         NtSetInformationFile        RegQueryValueExA   \n",
            "2  IsDebuggerPresent   GetSystemWindowsDirectoryW         NtQueryValueKey   \n",
            "3      WriteConsoleA                    NtOpenKey  LdrGetProcedureAddress   \n",
            "4         WSAStartup  SetUnhandledExceptionFilter      NtTerminateProcess   \n",
            "\n",
            "                        6                           7  ... Unnamed: 167  \\\n",
            "0       IsDebuggerPresent  GetSystemWindowsDirectoryW  ...          NaN   \n",
            "1  LdrGetProcedureAddress              CoUninitialize  ...          NaN   \n",
            "2             RegCloseKey          GetFileAttributesW  ...          NaN   \n",
            "3      NtTerminateProcess                     NtClose  ...          NaN   \n",
            "4                 NtClose     NtAllocateVirtualMemory  ...          NaN   \n",
            "\n",
            "  Unnamed: 168 Unnamed: 169 Unnamed: 170 Unnamed: 171 Unnamed: 172  \\\n",
            "0          NaN          NaN          NaN          NaN          NaN   \n",
            "1          NaN          NaN          NaN          NaN          NaN   \n",
            "2          NaN          NaN          NaN          NaN          NaN   \n",
            "3          NaN          NaN          NaN          NaN          NaN   \n",
            "4          NaN          NaN          NaN          NaN          NaN   \n",
            "\n",
            "  Unnamed: 173 Unnamed: 174 Unnamed: 175 Unnamed: 176  \n",
            "0          NaN          NaN          NaN          NaN  \n",
            "1          NaN          NaN          NaN          NaN  \n",
            "2          NaN          NaN          NaN          NaN  \n",
            "3          NaN          NaN          NaN          NaN  \n",
            "4          NaN          NaN          NaN          NaN  \n",
            "\n",
            "[5 rows x 177 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2570 entries, 0 to 2569\n",
            "Columns: 177 entries, sha256 to Unnamed: 176\n",
            "dtypes: int64(1), object(176)\n",
            "memory usage: 3.5+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar el dataset\n",
        "df = pd.read_csv(\"MalBehavD-V1-dataset.csv\")\n",
        "\n",
        "# Visualizar las primeras filas del dataset\n",
        "print(df.head())\n",
        "\n",
        "# Información del dataset\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYREByKDMXqP",
        "outputId": "a6f9b023-20b1-4764-b270-576327154939"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesamiento de texto\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'\\W', ' ', text)  # Eliminar caracteres especiales\n",
        "    text = re.sub(r'\\d+', ' ', text)  # Eliminar números\n",
        "    text = text.lower()  # Convertir a minúsculas\n",
        "    tokens = word_tokenize(text)  # Tokenización\n",
        "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]  # Stemming y eliminación de stopwords\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Concatenar las secuencias de llamadas a las APIs en una sola cadena de texto por fila\n",
        "df['api_sequence_text'] = df.drop(['sha256', 'labels'], axis=1).apply(lambda x: ' '.join(x.astype(str)), axis=1)\n",
        "\n",
        "# Preprocesamiento de texto\n",
        "df['api_sequence_text_processed'] = df['api_sequence_text'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "ZOcv3CrLMJk0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Vectorización del texto usando TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # Especificar el número máximo de características\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df['api_sequence_text_processed'])\n",
        "\n",
        "# Dividir los datos en características (X) y etiquetas (y)\n",
        "X = X_tfidf\n",
        "y = df['labels']"
      ],
      "metadata": {
        "id": "oWhu5z0wMpus"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, cross_validate\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "NeAmqbIwMtoD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# 4. Implementación y Validación de Modelos\n",
        "logistic_model = LogisticRegression()\n",
        "svm_model = SVC()\n",
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "models = [logistic_model, svm_model, rf_model]\n",
        "\n",
        "for model in models:\n",
        "    scores = cross_validate(model, X_train, y_train, cv=10, scoring=('accuracy', 'precision', 'recall', 'roc_auc'))\n",
        "    print(\"Model:\", model.__class__.__name__)\n",
        "    print(\"Accuracy:\", scores['test_accuracy'].mean())\n",
        "    print(\"Precision:\", scores['test_precision'].mean())\n",
        "    print(\"Recall:\", scores['test_recall'].mean())\n",
        "    print(\"ROC AUC:\", scores['test_roc_auc'].mean())\n",
        "\n",
        "# 5. Evaluación del Modelo en el Conjunto de Prueba\n",
        "best_model = max(models, key=lambda model: cross_val_score(model, X_train, y_train, cv=10).mean())\n",
        "best_model.fit(X_train, y_train)\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "print(\"Best Model:\", best_model.__class__.__name__)\n",
        "print(\"Accuracy on Test Set:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision on Test Set:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall on Test Set:\", recall_score(y_test, y_pred))\n",
        "print(\"ROC AUC on Test Set:\", roc_auc_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlZLgIzjOEym",
        "outputId": "a21f3c22-0c29-4495-c953-bbdf95993d44"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: LogisticRegression\n",
            "Accuracy: 0.9321942892613283\n",
            "Precision: 0.9591172795675522\n",
            "Recall: 0.9027465667915106\n",
            "ROC AUC: 0.9600575387298234\n",
            "Model: SVC\n",
            "Accuracy: 0.9344165114835505\n",
            "Precision: 0.9582263450359709\n",
            "Recall: 0.9082896379525593\n",
            "ROC AUC: 0.9694432135349738\n",
            "Model: RandomForestClassifier\n",
            "Accuracy: 0.9572004965859714\n",
            "Precision: 0.9812992510363436\n",
            "Recall: 0.9317478152309613\n",
            "ROC AUC: 0.9890591179523763\n",
            "Best Model: RandomForestClassifier\n",
            "Accuracy on Test Set: 0.9610894941634242\n",
            "Precision on Test Set: 0.9865229110512129\n",
            "Recall on Test Set: 0.9360613810741688\n",
            "ROC AUC on Test Set: 0.9614517431686633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Discusion de resultados**\n",
        "\n",
        "| Modelo                    | Accuracy | Precision | Recall  | ROC AUC |\n",
        "|---------------------------|----------|-----------|---------|---------|\n",
        "| Logistic Regression       | 0.9322   | 0.9591    | 0.9027  | 0.9601  |\n",
        "| Support Vector Machine    | 0.9344   | 0.9582    | 0.9083  | 0.9694  |\n",
        "| Random Forest             | 0.9572   | 0.9813    | 0.9317  | 0.9891  |\n",
        "\n",
        "\n",
        "En base a los resultados obtenidos, podemos observar que el modelo Random Forest supera a los otros dos modelos (Logistic Regression y Support Vector Machine) en todas las métricas evaluadas (Accuracy, Precision, Recall y ROC AUC) tanto en el conjunto de entrenamiento como en el conjunto de prueba.\n",
        "\n",
        "La precisión de un modelo es importante en el contexto de la detección de malware, ya que queremos minimizar los falsos positivos, es decir, identificar correctamente el malware sin clasificar incorrectamente software benigno como malicioso. El modelo Random Forest muestra una precisión superior en comparación con los otros modelos, lo que indica que es más efectivo para identificar correctamente el malware y reducir los falsos positivos.\n",
        "\n",
        "Además, el modelo Random Forest también muestra una mayor recall en comparación con los otros modelos. Un alto recall significa que el modelo es capaz de identificar la mayoría de las instancias de malware en el conjunto de datos, lo que es crucial en la detección de amenazas en seguridad.\n",
        "\n",
        "La combinación de alta precisión y alto recall, junto con un ROC AUC más alto, indica que el modelo Random Forest es capaz de encontrar un equilibrio óptimo entre la capacidad de identificar el malware y minimizar los falsos positivos, lo que lo convierte en el mejor modelo para este caso de detección de malware basado en la secuencia de llamadas a las APIs en este conjunto de datos específico."
      ],
      "metadata": {
        "id": "-dtonM4hPK1R"
      }
    }
  ]
}